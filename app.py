# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Svz30Guo77ZWCEqfGcF8mOAlKyKLbH2Q
"""


import streamlit as st
import pandas as pd
import numpy as np
import ast
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from nltk.stem.porter import PorterStemmer
import nltk

# Ensure NLTK packages are downloaded
nltk.download('punkt')

# ========== Load and Preprocess Your Data ==========
@st.cache_resource
def load_data():
    # Load your data
    movies = pd.read_csv('/content/drive/MyDrive/ML_dataset/tmdb_5000_movies.csv')
    credits = pd.read_csv('/content/drive/MyDrive/ML_dataset/tmdb_5000_credits.csv')

    # Merge datasets
    movies = movies.merge(credits, on='title')

    # Keep relevant columns
    movies = movies[['movie_id','title','overview','genres','keywords','cast','crew']]

    # Drop nulls
    movies.dropna(inplace=True)

    def convert(obj):
        L = []
        for i in ast.literal_eval(obj):
            L.append(i['name'])
        return L

    def convert3(obj):
        L = []
        counter = 0
        for i in ast.literal_eval(obj):
            if counter != 3:
                L.append(i['name'])
                counter += 1
            else:
                break
        return L

    def fetch_director(obj):
        L = []
        for i in ast.literal_eval(obj):
            if i['job'] == 'Director':
                L.append(i['name'])
                break
        return L

    ps = PorterStemmer()

    def stem(text):
        y = []
        for i in text.split():
            y.append(ps.stem(i))
        return " ".join(y)

    # Apply conversions
    movies['genres'] = movies['genres'].apply(convert)
    movies['keywords'] = movies['keywords'].apply(convert)
    movies['cast'] = movies['cast'].apply(convert3)
    movies['crew'] = movies['crew'].apply(fetch_director)
    movies['overview'] = movies['overview'].apply(lambda x: x.split())

    for feature in ['genres', 'keywords', 'cast', 'crew']:
        movies[feature] = movies[feature].apply(lambda x: [i.replace(" ", "") for i in x])

    movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']
    df = movies[['movie_id', 'title', 'tags']]
    df['tags'] = df['tags'].apply(lambda x: " ".join(x).lower())
    df['tags'] = df['tags'].apply(stem)

    # Vectorize
    cv = CountVectorizer(max_features=5000, stop_words='english')
    vectors = cv.fit_transform(df['tags']).toarray()

    similarity = cosine_similarity(vectors)

    return df, similarity

df, similarity = load_data()

# ========== Streamlit UI ==========
st.set_page_config(page_title="Movie Recommender", layout="centered")
st.title("ðŸŽ¬ Movie Recommendation System")
st.markdown("Get top 5 similar movies based on your favorite film.")

movie_input = st.text_input("Enter a movie name:")

if st.button("Recommend"):
    if movie_input.strip() == "":
        st.warning("Please enter a movie name.")
    elif movie_input not in df['title'].values:
        st.error("Movie not found in database. Try another title.")
    else:
        movie_index = df[df['title'] == movie_input].index[0]
        distances = similarity[movie_index]
        movie_list = sorted(list(enumerate(distances)), reverse=True, key=lambda x: x[1])[1:6]
        st.success("Top 5 recommendations:")
        for i in movie_list:
            st.write(f" {df.iloc[i[0]].title}")

from google.colab import drive

drive.mount('/content/drive')

movies = pd.read_csv('/content/drive/MyDrive/ML_dataset/tmdb_5000_movies.csv')
credits = pd.read_csv('/content/drive/MyDrive/ML_dataset/tmdb_5000_credits.csv')



